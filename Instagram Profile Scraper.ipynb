{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as reg\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from explicit import waiter, XPATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = webdriver.ChromeOptions()\n",
    "chrome_prefs = {}\n",
    "option.experimental_options[\"prefs\"] = chrome_prefs\n",
    "chrome_prefs[\"profile.default_content_settings\"] = {\"images\": 2}\n",
    "chrome_prefs[\"profile.managed_default_content_settings\"] = {\"images\": 2}\n",
    "\n",
    "driver = webdriver.Chrome(options=option,executable_path=r'path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Chrome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=r'path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(username, password):\n",
    "    driver.get('https://www.instagram.com/accounts/login/?source=auth_switcher')\n",
    "    # //*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[2]/div/label/input\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_name('username').send_keys(username)\n",
    "    driver.find_element_by_name('password').send_keys(password)\n",
    "    driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[4]/button/div').click()\n",
    "\n",
    "    driver.maximize_window()\n",
    "    \n",
    "username = 'username'\n",
    "password = 'password'\n",
    "login(username,password)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Open instagram account and get \n",
    "##### Number of Posts\n",
    "##### Followers\n",
    "##### Following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account ='global.influencers'\n",
    "driver.get(\"https://www.instagram.com/{0}\".format(account))\n",
    "\n",
    "page_soup = soup(driver.page_source,'lxml')\n",
    "posts = page_soup.findAll('span',{'class','g47SY'})\n",
    "post = posts[0].text\n",
    "followings = posts[2].text\n",
    "followers = posts[1].get('title')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape All Followers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_followers(driver, account):\n",
    "    # Load account page\n",
    "    driver.get(\"https://www.instagram.com/{0}/\".format(account))\n",
    "\n",
    "    followersLink = driver.find_element_by_css_selector('ul li a')\n",
    "    followersLink.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    waiter.find_element(driver, \"//div[@role='dialog']\", by=XPATH)\n",
    "\n",
    "    follower_css = \"ul div li:nth-child({}) a.notranslate\"  # Taking advange of CSS's nth-child functionality\n",
    "    for group in itertools.count(start=1, step=12):\n",
    "        for follower_index in range(group, group + 12):\n",
    "            yield waiter.find_element(driver, follower_css.format(follower_index)).text\n",
    "\n",
    "        last_follower = waiter.find_element(driver, follower_css.format(follower_index))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", last_follower)\n",
    "        \n",
    "Followers = []\n",
    "for count, follower in enumerate(scrape_followers(driver, account=account), 1):\n",
    "    Data = {}\n",
    "    Data ['Followers'] = \"https://www.instagram.com/\"+follower\n",
    "    Followers.append(Data)\n",
    "    if count >= int(followers):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape All Followings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_followings(driver, account):\n",
    "    # Load account page\n",
    "    driver.get(\"https://www.instagram.com/{0}/\".format(account))\n",
    "\n",
    "    followersLink = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/header/section/ul/li[3]/a')\n",
    "    followersLink.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    waiter.find_element(driver, \"//div[@role='dialog']\", by=XPATH)\n",
    "\n",
    "    follower_css = \"ul div li:nth-child({}) a.notranslate\"  # Taking advange of CSS's nth-child functionality\n",
    "    for group in itertools.count(start=1, step=12):\n",
    "        for follower_index in range(group, group + 12):\n",
    "            yield waiter.find_element(driver, follower_css.format(follower_index)).text\n",
    "\n",
    "        last_follower = waiter.find_element(driver, follower_css.format(follower_index))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", last_follower)\n",
    "\n",
    "Followings = []\n",
    "for count, following in enumerate(scrape_followings(driver, account=account), 1):\n",
    "    Data = {}\n",
    "    Data['Followings'] = \"https://www.instagram.com/\"+following\n",
    "    Followings.append(Data)\n",
    "    if count >= int(followings):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape All Posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_Posts_URL(driver , account):\n",
    "    \n",
    "    page_soup = soup(driver.page_source,'lxml')\n",
    "    Posts_links = []\n",
    "    Tagged_in_Posts = page_soup.findAll('div',{'class','Nnq7C weEfm'})\n",
    "\n",
    "    i = 0\n",
    "    while(i <int(post)):\n",
    "        print(len(Tagged_in_Posts),i)\n",
    "        i+=len(Tagged_in_Posts)\n",
    "        for posts in Tagged_in_Posts:\n",
    "            post_links  = posts.findAll('a') \n",
    "            for link in post_links:\n",
    "                Data ={}\n",
    "                Data['Post Links'] = 'https://www.instagram.com/'+link.get('href')\n",
    "                Posts_links.append(Data)            \n",
    "\n",
    "        scroll = driver.find_element_by_tag_name('html')\n",
    "        scroll.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        Tagged_in_Posts = page_soup.findAll('div',{'class','Nnq7C weEfm'})\n",
    "        page_soup = soup(driver.page_source,'lxml')\n",
    "\n",
    "    return Posts_links\n",
    "    \n",
    "posts_url = scrape_Posts_URL(driver,account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape All Tagged In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_Tagged_in_Posts_URL(driver , account):\n",
    "    driver.get(\"https://www.instagram.com/\"+account+'/tagged')\n",
    "    page_soup = soup(driver.page_source,'lxml')\n",
    "    Posts_links = []\n",
    "    Tagged_in_Posts = page_soup.findAll('div',{'class','Nnq7C weEfm'})\n",
    "    time.sleep(2)\n",
    "    flag = True\n",
    "    while(flag):\n",
    "        print(len(Tagged_in_Posts))\n",
    "        if(flag==True):\n",
    "            for posts in Tagged_in_Posts:\n",
    "                post_links  = posts.findAll('a') \n",
    "                if(flag==True):\n",
    "                    for link in post_links:\n",
    "                        Data ={}\n",
    "                        url = 'https://www.instagram.com/'+link.get('href')\n",
    "                        Data['Post Links'] = url\n",
    "                        Posts_links.append(Data)\n",
    "                        if(url == 'https://www.instagram.com//p/BeKwrKDFLq9/'):\n",
    "                            flag = False\n",
    "\n",
    "        scroll = driver.find_element_by_tag_name('html')\n",
    "        scroll.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        Tagged_in_Posts = page_soup.findAll('div',{'class','Nnq7C weEfm'})\n",
    "        page_soup = soup(driver.page_source,'lxml')\n",
    "\n",
    "    return Posts_links\n",
    "\n",
    "tagged_posts_url = scrape_Tagged_in_Posts_URL(driver,account)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
